<?xml version="1.0"?>
<launch>

    <arg name="status_output" default="screen"/>

    <!-- Get the machine file -->
    <arg name="machine" default="localhost"/>
    <include file="$(env ROBOT_BRINGUP_PATH)/machines/$(arg machine).machine" />

    <!-- Always run a multicast server with a string topic answerer for amigo-hear -->
    <node name="hmi" pkg="hmi" type="multi_client" machine="$(arg machine)" output="$(arg status_output)"/>

    <!-- Kaldi model path default to ~/data/kaldi_speech_recognition -->
    <arg name="model_path" default="$(env HOME)/data/kaldi_speech_recognition/"/>
    <param name="/kaldi_model_path" type="string" value="/home/amigo/ros/kinetic/system/src/speech_recognition/gstreamer_live_spr/online-data/models/tri2b_mmi/"/>
    <!--<param name="/kaldi_model_path" type="string" value="$(arg model_path)"/>-->

    <group ns="hmi">

        <!-- QR-code / amigo-hear -->
        <node name="string_topic_answerer" pkg="hmi" type="string_topic_answerer" output="$(arg status_output)"/>

        <!-- If we are on the real robot, launch the server, otherwise a dummy -->
        <node name="kaldi_speech_recognition" pkg="speech_recognition" type="hmi_kaldi_node" machine="$(arg machine)" output="$(arg status_output)">
            <!-- <rosparam command="load" file="$(env ROBOT_BRINGUP_PATH)/parameters/interaction/speech_client.yaml" /> -->
        </node>

    </group> <!-- ns="hmi" -->

</launch>
